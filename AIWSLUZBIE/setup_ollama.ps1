# Kompletny skrypt setup Ollama dla Windows
# Uruchom: .\setup_ollama.ps1

Write-Host "üîß Konfiguracja Ollama dla HackNation" -ForegroundColor Cyan
Write-Host "=" * 50

# Krok 1: Dodaj do PATH
Write-Host "`n[1/4] Dodawanie Ollama do PATH..." -ForegroundColor Yellow
$ollamaPath = "$env:LOCALAPPDATA\Programs\Ollama"

if (Test-Path "$ollamaPath\ollama.exe") {
    # Dodaj do PATH u≈ºytkownika (na sta≈Çe)
    $currentPath = [Environment]::GetEnvironmentVariable("Path", "User")
    if ($currentPath -notlike "*$ollamaPath*") {
        [Environment]::SetEnvironmentVariable(
            "Path",
            $currentPath + ";$ollamaPath",
            "User"
        )
        Write-Host "‚úÖ Ollama dodane do PATH" -ForegroundColor Green
    } else {
        Write-Host "‚úÖ Ollama ju≈º jest w PATH" -ForegroundColor Green
    }
    
    # Dodaj do PATH bie≈ºƒÖcej sesji
    $env:Path += ";$ollamaPath"
} else {
    Write-Host "‚ùå Ollama nie znaleziono w: $ollamaPath" -ForegroundColor Red
    Write-Host "   Zainstaluj z: https://ollama.ai/download" -ForegroundColor Yellow
    exit 1
}

# Krok 2: Sprawd≈∫ wersjƒô
Write-Host "`n[2/4] Sprawdzanie wersji..." -ForegroundColor Yellow
try {
    $version = ollama --version
    Write-Host "‚úÖ $version" -ForegroundColor Green
} catch {
    Write-Host "‚ùå B≈ÇƒÖd: $_" -ForegroundColor Red
    exit 1
}

# Krok 3: Sprawd≈∫ czy serwer dzia≈Ça
Write-Host "`n[3/4] Sprawdzanie serwera..." -ForegroundColor Yellow
try {
    $response = Invoke-WebRequest -Uri "http://localhost:11434/api/tags" -TimeoutSec 2 -ErrorAction Stop
    Write-Host "‚úÖ Serwer Ollama dzia≈Ça!" -ForegroundColor Green
    $serverRunning = $true
} catch {
    Write-Host "‚ö†Ô∏è Serwer nie dzia≈Ça - uruchom w osobnym terminalu:" -ForegroundColor Yellow
    Write-Host "   ollama serve" -ForegroundColor Cyan
    $serverRunning = $false
}

# Krok 4: Sprawd≈∫ modele
Write-Host "`n[4/4] Sprawdzanie zainstalowanych modeli..." -ForegroundColor Yellow
try {
    $models = ollama list
    if ($models -match "llama3.2|mistral|codellama") {
        Write-Host "‚úÖ Modele znalezione:" -ForegroundColor Green
        Write-Host $models
    } else {
        Write-Host "‚ö†Ô∏è Brak modeli - pobierz model:" -ForegroundColor Yellow
        Write-Host "   ollama pull llama3.2" -ForegroundColor Cyan
    }
} catch {
    Write-Host "‚ö†Ô∏è Nie mo≈ºna sprawdziƒá modeli (serwer mo≈ºe nie dzia≈Çaƒá)" -ForegroundColor Yellow
}

# Podsumowanie
Write-Host "`n" + "=" * 50
Write-Host "‚úÖ Konfiguracja zako≈Ñczona!" -ForegroundColor Green
Write-Host "`nüìù Nastƒôpne kroki:" -ForegroundColor Cyan
if (-not $serverRunning) {
    Write-Host "   1. Uruchom serwer: ollama serve" -ForegroundColor White
}
Write-Host "   2. Pobierz model: ollama pull llama3.2" -ForegroundColor White
Write-Host "   3. U≈ºyj w Pythonie: create_demo_assistant(use_local_model=True)" -ForegroundColor White
Write-Host "`nüí° Wskaz√≥wka: Zrestartuj terminal aby PATH zadzia≈Ça≈Ç wszƒôdzie" -ForegroundColor Yellow


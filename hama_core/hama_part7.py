"""
ğŸš€ HAMA DIAMOND - CZÄ˜ÅšÄ† 7: URUCHOMIENIE TESTÃ“W
Gotowe do wklejenia w Google Colab
"""

# ============================================================================
# IMPORTY
# ============================================================================

import json
import sys
import os

# Opcjonalne importy
try:
    import numpy as np  # type: ignore
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    # Fallback dla numpy
    class np:  # type: ignore
        @staticmethod
        def mean(data):
            return sum(data) / len(data) if data else 0

try:
    from tqdm import tqdm  # type: ignore
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    # Fallback dla tqdm
    def tqdm(iterable, *args, **kwargs):
        return iterable

# Import klas z innych czÄ™Å›ci HAMA Diamond
# ZakÅ‚adamy, Å¼e wszystkie czÄ™Å›ci sÄ… w tym samym katalogu
try:
    from hama_part5 import EnhancedCognitiveAgent  # type: ignore
except ImportError:
    # JeÅ›li import bezpoÅ›redni nie dziaÅ‚a, prÃ³buj z sys.path
    sys.path.insert(0, os.path.dirname(__file__))
    from hama_part5 import EnhancedCognitiveAgent  # type: ignore

try:
    from hama_part6 import GeminiCognitiveAdapter, HAMADiamondTests  # type: ignore
except ImportError:
    sys.path.insert(0, os.path.dirname(__file__))
    from hama_part6 import GeminiCognitiveAdapter, HAMADiamondTests  # type: ignore

# gemini_model moÅ¼e byÄ‡ None - uÅ¼ywamy lokalnego adaptera Ollama
gemini_model = None

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  ğŸ’ HAMA DIAMOND TESTS ğŸ’                        â•‘
â•‘         Comprehensive Cognitive Architecture Evaluation          â•‘
â•‘                                                                  â•‘
â•‘  G - Generalization (Transfer Learning)                         â•‘
â•‘  Q - Quality (Adversarial Robustness)                           â•‘
â•‘  P - Performance (Speed & Memory Efficiency)                    â•‘
â•‘  A - Adaptation (Meta-Learning)                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# ============================================================================
# INICJALIZACJA
# ============================================================================

print("\n[1/7] Inicjalizacja Enhanced Cognitive Agent...")
agent = EnhancedCognitiveAgent()
print(f"âœ… Agent utworzony")
print(f"   Learning Progress: {agent.emergent_integrator.get_integration_status()['emergent_metrics']['learning_progress']*100:.1f}%")

print("\n[2/7] Konfiguracja Gemini Adapter...")
adapter = GeminiCognitiveAdapter(gemini_model, agent)
print("âœ… Adapter skonfigurowany")

print("\n[3/7] Bootstrap - Agent uczy siÄ™ podstaw...")
for i in tqdm(range(50), desc="Bootstrap phase"):
    agent.cognitive_cycle()

print(f"âœ… Bootstrap zakoÅ„czony")
print(f"   Cycles: {agent.cycle_count}")
print(f"   World objects: {len(agent.world_model.objects)}")
print(f"   Episodes: {len(agent.memory.episodic_memory)}")

# ============================================================================
# HAMA DIAMOND TESTS
# ============================================================================

print("\n[4/7] Inicjalizacja HAMA Diamond Tests...")
hama = HAMADiamondTests(agent, adapter)
print("âœ… HAMA Diamond tester gotowy")

print("\n" + "="*70)
print("ROZPOCZÄ˜CIE TESTÃ“W HAMA DIAMOND")
print("="*70)

# TEST G: GENERALIZATION
print("\n[5/7] Running TEST G: GENERALIZATION...")
g_results = hama.test_generalization(n_cycles=50)

# TEST Q: QUALITY
print("\n[5/7] Running TEST Q: QUALITY...")
q_results = hama.test_quality(n_trials=20)

# TEST P: PERFORMANCE
print("\n[5/7] Running TEST P: PERFORMANCE...")
p_results = hama.test_performance(n_cycles=200)

# TEST A: ADAPTATION
print("\n[5/7] Running TEST A: ADAPTATION...")
a_results = hama.test_adaptation(n_tasks=5)

# ============================================================================
# RAPORT I WIZUALIZACJE
# ============================================================================

print("\n[6/7] Generowanie raportu...")
report = hama.generate_hama_report()

print("\n[7/7] Tworzenie wizualizacji...")
hama.plot_hama_results()

# ============================================================================
# DODATKOWE ANALIZY
# ============================================================================

print("\n" + "="*70)
print("DODATKOWE ANALIZY")
print("="*70)

# Gemini Integration Test
print("\nğŸ¤– Test integracji z Gemini...")
test_questions = [
    "What have you learned during these tests?",
    "Describe your cognitive capabilities.",
    "What is your strongest skill?"
]

gemini_responses = []
for question in test_questions:
    print(f"\nQ: {question}")
    response = adapter.cognitive_query(question)
    if response['success']:
        print(f"A: {response['response'][:200]}...")
        gemini_responses.append(response)
    else:
        print(f"Error: {response['error']}")

gemini_stats = adapter.get_interaction_statistics()
print(f"\nğŸ“Š Gemini Statistics:")
print(f"   Total interactions: {gemini_stats.get('total_interactions', 0)}")
print(f"   Success rate: {gemini_stats.get('successful', 0)}/{gemini_stats.get('total_interactions', 0)}")
print(f"   Avg latency: {gemini_stats.get('avg_latency', 0)*1000:.0f}ms")

# Agent Final State
print("\nğŸ§  Agent Final State:")
final_state = agent.get_enhanced_state_summary()
print(f"   Total Cycles: {final_state['cycle']}")
print(f"   World Objects: {final_state['world_objects']}")
print(f"   Episodes: {final_state['episodes']}")
print(f"   Behavior Mode: {final_state['adaptive_behavior_mode']}")
print(f"   Learning Progress: {final_state['emergent_metrics']['learning_progress']*100:.1f}%")
print(f"   Chaos Level: {final_state['emergent_metrics']['chaos_level']:.3f}")
print(f"   Cognitive Complexity: {final_state['emergent_metrics']['cognitive_complexity']:.3f}")

# Semantic Memory Analysis
print("\nğŸ“š Semantic Memory Analysis:")
semantic_stats = agent.memory.get_semantic_statistics()  # type: ignore
print(f"   Total concepts: {semantic_stats['total_concepts']}")
print(f"   Concept types:")
for concept_type, count in semantic_stats['by_type'].items():
    print(f"     - {concept_type}: {count}")

if semantic_stats['most_common']:
    print(f"   Top concepts:")
    for concept, count in semantic_stats['most_common'][:3]:
        print(f"     - {concept[:40]}: {count}x")

# ============================================================================
# PODSUMOWANIE KOÅƒCOWE
# ============================================================================

print("\n" + "ğŸ’"*35)
print("HAMA DIAMOND - PODSUMOWANIE KOÅƒCOWE")
print("ğŸ’"*35 + "\n")

scores = report['hama_scores']
overall = report['overall_score']
grade = report['grade']

print("ğŸ“Š HAMA DIAMOND SCORES:")
print(f"   G (Generalization):  {scores['G']*100:>5.1f}/100  {'âœ…' if scores['G'] >= 0.7 else 'âš ï¸'}")
print(f"   Q (Quality):         {scores['Q']*100:>5.1f}/100  {'âœ…' if scores['Q'] >= 0.7 else 'âš ï¸'}")
print(f"   P (Performance):     {scores['P']*100:>5.1f}/100  {'âœ…' if scores['P'] >= 0.7 else 'âš ï¸'}")
print(f"   A (Adaptation):      {scores['A']*100:>5.1f}/100  {'âœ…' if scores['A'] >= 0.7 else 'âš ï¸'}")
print(f"\n   OVERALL SCORE:       {overall*100:>5.1f}/100")
print(f"   GRADE:               {grade}")

# PorÃ³wnanie z baseline
baseline_score = 0.65
improvement = ((overall - baseline_score) / baseline_score) * 100
print(f"\nğŸ“ˆ VS BASELINE:")
print(f"   Baseline score: {baseline_score*100:.1f}/100")
print(f"   Improvement: {improvement:+.1f}%")

# Kluczowe osiÄ…gniÄ™cia
print("\nğŸ¯ KEY ACHIEVEMENTS:")
achievements = []

if scores['G'] >= 0.7:
    achievements.append("âœ… Strong transfer learning")
if scores['Q'] >= 0.7:
    achievements.append("âœ… High adversarial robustness")
if scores['P'] >= 0.7:
    achievements.append("âœ… Efficient performance")
if scores['A'] >= 0.7:
    achievements.append("âœ… Meta-learning capability")
if final_state['emergent_metrics']['learning_progress'] >= 0.5:
    achievements.append("âœ… Significant learning progress")
if len(agent.memory.semantic_memory) >= 50:  # type: ignore
    achievements.append("âœ… Rich semantic memory")

for achievement in achievements:
    print(f"   {achievement}")

print("\nğŸ“ FILES GENERATED:")
print("   1. hama_diamond_report.json")
print("   2. hama_diamond_results.png")

print("\n" + "="*70)
print("âœ… HAMA DIAMOND TESTS COMPLETED SUCCESSFULLY!")
print("="*70)

# ============================================================================
# OPTIONAL: Extended Analysis
# ============================================================================

print("\n" + "="*70)
print("OPTIONAL: Extended Analysis Functions")
print("="*70)

def analyze_learning_curve():
    """Analiza krzywej uczenia"""
    print("\nğŸ“ˆ Learning Curve Analysis:")
    metrics = agent.emergent_integrator.get_integration_status()['emergent_metrics']
    print(f"   Learning progress: {metrics['learning_progress']*100:.1f}%")
    print(f"   Performance trend: {metrics['performance_trend']:.3f}")
    print(f"   Adaptation speed: {metrics['adaptation_speed']:.3f}")

def compare_with_benchmarks():
    """PorÃ³wnanie z benchmarkami"""
    print("\nğŸ† Benchmark Comparison:")
    benchmarks = {
        'Pure LSTM': {'G': 0.45, 'Q': 0.40, 'P': 0.60, 'A': 0.35},
        'Transformer': {'G': 0.65, 'Q': 0.55, 'P': 0.70, 'A': 0.50},
        'HAMA2+Cognitive': scores
    }
    
    for name, benchmark_scores in benchmarks.items():
        avg = np.mean(list(benchmark_scores.values()))
        print(f"   {name:20s}: {avg*100:.1f}/100")

def export_agent_state():
    """Eksport stanu agenta"""
    state = {
        'final_state': agent.get_enhanced_state_summary(),
        'memory_stats': agent.memory.get_semantic_statistics(),  # type: ignore[attr-defined]
        'emergent_metrics': agent.emergent_integrator.get_integration_status()['emergent_metrics'],
        'gemini_stats': adapter.get_interaction_statistics()
    }
    
    with open('agent_final_state.json', 'w') as f:
        json.dump(state, f, indent=2, default=str)
    
    print("\nğŸ’¾ Agent state exported: agent_final_state.json")

# Uruchom extended analysis
print("\nRunning extended analysis...")
analyze_learning_curve()
compare_with_benchmarks()
export_agent_state()

print("\n" + "ğŸ‰"*35)
print("ALL DONE! ğŸ‰")
print("ğŸ‰"*35)
print("\nAgent is ready for production use!")
print(f"Final Grade: {grade}")
print(f"Overall Score: {overall*100:.1f}/100")
